{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m inputPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mISCX-Dataset-Full\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mISCX - without normalize\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload( inputPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train-withoutnormalize-740features.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(inputPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_test-withoutnormalize-740features.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(inputPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train-withoutnormalize-740features.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(fid, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[0;32m    457\u001b[0m                                  pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs,\n\u001b[0;32m    458\u001b[0m                                  max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfromfile(fp, dtype\u001b[38;5;241m=\u001b[39mdtype, count\u001b[38;5;241m=\u001b[39mcount)\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputPath = 'D:\\\\ISCX-Dataset-Full\\ISCX - without normalize\\\\'\n",
    "\n",
    "x_train = np.load( inputPath + \"x_train-withoutnormalize-740features.npy\")\n",
    "x_test = np.load(inputPath + \"x_test-withoutnormalize-740features.npy\")\n",
    "\n",
    "y_train = np.load(inputPath + \"y_train-withoutnormalize-740features.npy\", allow_pickle=True)\n",
    "y_test = np.load(inputPath + \"y_test-withoutnormalize-740features.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "y_train = torch.argmax(torch.tensor(y_train), dim=1)\n",
    "y_test = torch.argmax(torch.tensor(y_test), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "x_train = pd.DataFrame(x_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.DataFrame(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afif\\AppData\\Local\\Temp\\ipykernel_27252\\2009267275.py:4: DtypeWarning: Columns (740) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(inputPath + \"ISCX_Preprocesswithoutnormalize740Byte.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scp': 0, 'sftp': 1, 'facebook': 2, 'email': 3, 'youtube': 4, 'spotify': 5, 'aimchat': 6, 'voipbuster': 7, 'skype': 8, 'vimeo': 9}\n",
      "<bound method NDFrame.head of          B0  B1  B2   B3   B4   B5  B6  B7  B8  B9  ...  B731  B732  B733  \\\n",
      "0        69  16   0  100   85  213  64   0  64   6  ...     0     0     0   \n",
      "1        69  16   0  100  131  184  64   0  64   6  ...     0     0     0   \n",
      "2        69  16   0   52   85  214  64   0  64   6  ...     0     0     0   \n",
      "3        69   0   0   60  245   37  64   0  64   6  ...     0     0     0   \n",
      "4        69   0   0   60    0    0  64   0  64   6  ...     0     0     0   \n",
      "...      ..  ..  ..  ...  ...  ...  ..  ..  ..  ..  ...   ...   ...   ...   \n",
      "2434571  69   0   0   98  237  168  64   0  64   6  ...     0     0     0   \n",
      "2434572  69   0   0   52  217  125   0   0  55   6  ...     0     0     0   \n",
      "2434573  69   0   0   52  106   64   0   0  55   6  ...     0     0     0   \n",
      "2434574  69   0   0   57  175  143  64   0  64  17  ...     0     0     0   \n",
      "2434575  69   0   0  241  200  118   0   0  63  17  ...     0     0     0   \n",
      "\n",
      "         B734  B735  B736  B737  B738  B739  label  \n",
      "0           0     0     0     0     0     0      0  \n",
      "1           0     0     0     0     0     0      0  \n",
      "2           0     0     0     0     0     0      0  \n",
      "3           0     0     0     0     0     0      0  \n",
      "4           0     0     0     0     0     0      0  \n",
      "...       ...   ...   ...   ...   ...   ...    ...  \n",
      "2434571     0     0     0     0     0     0      4  \n",
      "2434572     0     0     0     0     0     0      4  \n",
      "2434573     0     0     0     0     0     0      4  \n",
      "2434574     0     0     0     0     0     0      4  \n",
      "2434575     0     0     0     0     0     0      4  \n",
      "\n",
      "[2434576 rows x 741 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputPath = 'D:\\\\ISCX-Dataset-Full\\ISCX - without normalize\\\\'\n",
    "\n",
    "df = pd.read_csv(inputPath + \"ISCX_Preprocesswithoutnormalize740Byte.csv\")\n",
    "df['label'] = df['label'].fillna('skype')\n",
    "df['label'] = df['label'].replace({'skypefile': 'skype', 'skypeaudio': 'skype', 'skypechat': 'skype'})\n",
    "df['label'] = df['label'].replace({'facebookaudio': 'facebook', 'facebookChat': 'facebook', 'facebookVideo': 'facebook', 'facebookvideo': 'facebook'})\n",
    "\n",
    "\n",
    "\n",
    "class_mapping = {label: i for i, label in enumerate(df['label'].unique())}\n",
    "# Replace class labels with numbers\n",
    "df['label'] = df['label'].replace(class_mapping)\n",
    "print(class_mapping)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(inputPath + \"ISCX_Preprocesswithoutnormalize740ByteUnlabelled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "8    276708\n",
      "2    276565\n",
      "1    128752\n",
      "0    117007\n",
      "7    101512\n",
      "4    100969\n",
      "5     40775\n",
      "3     23784\n",
      "9     21757\n",
      "6      2473\n",
      "Name: count, dtype: int64\n",
      "(872241, 741)\n",
      "(109031, 741)\n",
      "(109030, 741)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "inputPath = 'D:\\\\ISCX-Dataset-Full\\ISCX - without normalize\\\\'\n",
    "\n",
    "df = pd.read_csv(inputPath + \"ISCX_Preprocesswithoutnormalize740ByteUnlabelledDownsampled.csv\", index_col=0)\n",
    "\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "print(label_counts)\n",
    "\n",
    "x = df.iloc[:, ::740]\n",
    "y = df['label']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# print(f\"Training set size: {len(x_train)}\")\n",
    "# print(f\"Testing set size: {len(x_test)}\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1090302, 742)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(inputPath + \"x_train-withoutnormalize-740ByteUnlabelledDownsampled.npy\", x_train)\n",
    "np.save(inputPath + \"x_test-withoutnormalize-740ByteUnlabelledDownsampled.npy\", x_test)\n",
    "np.save(inputPath + \"y_train-withoutnormalize-740ByteUnlabelledDownsampled.npy\", y_train)\n",
    "np.save(inputPath + \"y_test-withoutnormalize-740ByteUnlabelledDownsamplednpy\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.6 MiB for an array with shape (2434576,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m inputPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mISCX-Dataset-Full\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mISCX - without normalize\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(inputPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISCX_Preprocesswithoutnormalize740Byte.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m quantities \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m276708\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msftp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m276565\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myoutube\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100969\u001b[39m,\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to store the filtered rows\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:376\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    374\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m concat_compat(arrs)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_cat_dtypes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result[name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m    378\u001b[0m         warning_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(name))\n",
      "File \u001b[1;32mc:\\Users\\afif\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:78\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     77\u001b[0m     to_concat_arrs \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[np.ndarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(to_concat_arrs, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.6 MiB for an array with shape (2434576,) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputPath = 'D:\\\\ISCX-Dataset-Full\\ISCX - without normalize\\\\'\n",
    "\n",
    "df = pd.read_csv(inputPath + \"ISCX_Preprocesswithoutnormalize740ByteUnlabelledDownsampled.csv\")\n",
    "\n",
    "quantities = {\n",
    "    \"scp\": 276708,\n",
    "    \"sftp\": 276565,\n",
    "    \"facebook\": 128752,\n",
    "    \"email\": 117007,\n",
    "    \"youtube\": 100969,\n",
    "}\n",
    "\n",
    "# Create a DataFrame to store the filtered rows\n",
    "filtered_dfs = []\n",
    "\n",
    "# Loop through each label and select the specified quantity\n",
    "for label, quantity in quantities.items():\n",
    "    # Filter rows for the current label and select the top rows based on the quantity\n",
    "    filtered_df = df[df['label'] == label].head(quantity)\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "# Concatenate the filtered rows for the specified labels\n",
    "final_filtered_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 1704203\n",
      "Testing sample size: 730373\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "# Print sizes of the training and testing samples\n",
    "print(f\"Training sample size: {len(train_df)}\")\n",
    "print(f\"Testing sample size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(inputPath + \"train-withoutnormalize-740featuresUnlabelledDownsampled.npy\", train_df)\n",
    "np.save(inputPath + \"test-withoutnormalize-740featuresUnlabelledDownsampled.npy\", test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved with custom spacing.\n"
     ]
    }
   ],
   "source": [
    "with open('dev.txt', 'w') as f:\n",
    "    for index, row in val_df.iterrows():\n",
    "        # Use .iloc for positional indexing\n",
    "        line = ' '.join(map(str, row.iloc[:-1])) + '\\t' + str(row.iloc[-1]) + '\\n'\n",
    "        f.write(line)\n",
    "\n",
    "print(\"File saved with custom spacing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
